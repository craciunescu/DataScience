%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{Sweave}

\title{G4.P-1}
\author{David Emanuel Craciunescu \and Laura P<e9>rez Medeiro}

\begin{document}
\input{PL3-G4-concordance}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Data analysis using Hunt decision algorithm and linear regression}

  \subsection{}The data use in this exercise will be nine students marks and califications, as it has been done in the teorical classes. For this analysis, it wil be used the gain information meause, using Gini as the impurity measure.
 
  First step in the analysis is read the data, which is contains in a txt file called qualifications.txt:
 
\begin{Schunk}
\begin{Sinput}
> library(utils)
> qualifications <- read.table("qualification.txt")
> sample = data.frame(qualifications)
\end{Sinput}
\end{Schunk}

In order to make the analysis, the package rpart will be used. this means, that it should be install before working with the dataset. In order to manage R packages, it will be used Packrat
 <<>>=
library(utils)
library(rpart)
clasification = rpart(C.G~.,data=sample, method="class", minsplit = 1)
clasification

Another package that can be used to do this analysis is tree:

library(tree)
(clasificationTree = tree(C.G~., data = sample, mincut = 1, minsize = 2))
clasificationTree


 
  \subsection{} In this second part, tha dataset use is planets.txt. To this dataset, linear regression will be applied.
  
As it has been done before, the first step consist on reading data from a \textit{txt} file:
 
\begin{Schunk}
\begin{Sinput}
> data <- read.table("planets.txt")
> data = data.frame(data)
> names(data)
\end{Sinput}
\begin{Soutput}
[1] "Radius"  "Density"
\end{Soutput}
\end{Schunk}

In order to quantify the correlation between the variables, it will be calculated the coeficient's matrix correlation:

\begin{Schunk}
\begin{Sinput}
> cor(data)
\end{Sinput}
\begin{Soutput}
          Radius  Density
Radius  1.000000 0.371063
Density 0.371063 1.000000
\end{Soutput}
\end{Schunk}

Then, it will be calculated and representated the minimun square error line:
\begin{Schunk}
\begin{Sinput}
> regression <- lm( Density~Radius, data)
> summary(regression)
\end{Sinput}
\begin{Soutput}
Call:
lm(formula = Density ~ Radius, data = data)

Residuals:
Mercurio    Venus   Tierra    Marte 
 0.70312 -0.01253  0.24566 -0.93624 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)  
(Intercept)   4.3624     1.2050   3.620   0.0685 .
Radius        0.1394     0.2466   0.565   0.6289  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.846 on 2 degrees of freedom
Multiple R-squared:  0.1377,	Adjusted R-squared:  -0.2935 
F-statistic: 0.3193 on 1 and 2 DF,  p-value: 0.6289
\end{Soutput}
\end{Schunk}

The equation's line is y = 4.3624 + 0.1394x

\begin{Schunk}
\begin{Sinput}
> library(gplots)
> par(mar = rep(2,4))
> plot(data$Density, data$Radius)
> abline(regression)
\end{Sinput}
\end{Schunk}

Finally, it is necessary to calculate ANOVA in order to analysize correctly the relation between variables.

\begin{Schunk}
\begin{Sinput}
> anova <- aov(Density~Radius, data) 
> summary(anova)
\end{Sinput}
\begin{Soutput}
            Df Sum Sq Mean Sq F value Pr(>F)
Radius       1 0.2286  0.2286   0.319  0.629
Residuals    2 1.4314  0.7157               
\end{Soutput}
\end{Schunk}

\section{} The following part consist on doing the same analysis as it has been done before, but now with new datasets.
 <<>>=
data <- read.table("vehiculos.txt")
sample = data.frame(data)
library(rpart)
clasification = rpart(TipoVehiculo~.,data=sample, method="class", minsplit = 1)
clasification
\end{document}
